library(raster)
library(sp)#
library(rgdal)#
library(rgeos)#
library(mapview)#
library(caret)#
library(randomForest)#
library(nnet)
#set up directory for oneida data folder#
dirR <- "~/Downloads/mmaloney/a07"#
#
#read in Sentinel data#
#
rdatB2 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B02_20m.tif"))#
rdatB3 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B03_20m.tif"))#
rdatB4 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B04_20m.tif"))#
rdatB5 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B05_20m.tif"))#
rdatB6 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B06_20m.tif"))#
rdatB7 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B07_20m.tif"))#
rdatB8 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B08_20m.tif"))#
rdatB11 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B11_20m.tif"))#
rdatB12 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B12_20m.tif"))#
clouds <- raster(paste0(dirR,"/sentinel/MSK_CLDPRB_20m.tif"))#
#
#read in validation data#
#here verbose=FALSE hiddes#
algae <- readOGR(paste0(dirR,"/Oneida/algae.shp"), verbose=FALSE)#
agri <- readOGR(paste0(dirR,"/Oneida/agriculture.shp"), verbose=FALSE)#
built <- readOGR(paste0(dirR,"/Oneida/built.shp"), verbose=FALSE)#
forest <- readOGR(paste0(dirR,"/Oneida/forest.shp"), verbose=FALSE)#
water <- readOGR(paste0(dirR,"/Oneida/water.shp"), verbose=FALSE)#
wetlands <- readOGR(paste0(dirR,"/Oneida/wetlands.shp"), verbose=FALSE)#
#
#stack red green blue#
rgbS <- stack(rdatB4,rdatB3,rdatB2)#
#stack all raster data#
allbands <- stack(rdatB2,rdatB3,rdatB4,rdatB5,rdatB6,rdatB7, rdatB8,rdatB11, rdatB12,clouds)#
#
#view raster, maximum digigtal is around 20000 so set scale to that#
plotRGB(rgbS, scale=20000)
plot(allbands[[10]])
allbandsCloud <- list()#
for(i in 1:9){#
  allbandsCloud[[i]] <- setValues(allbands[[i]],#
                                  ifelse(getValues(allbands[[10]])>60,NA,getValues(allbands[[i]])))#
}#
allbandsCloudf <- stack(allbandsCloud[[1]],allbandsCloud[[2]],allbandsCloud[[3]],allbandsCloud[[4]],allbandsCloud[[5]],allbandsCloud[[6]],allbandsCloud[[7]],allbandsCloud[[8]],allbandsCloud[[9]])
set.seed(12153)#
#
#make a vector that indicates which of our our 120 points are going to be training vs validation data for each point.#
#randomly select #
algSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
algData <- rep("train",120)#
#randomly replace half of the data to be validating data#
algData[algSamp] <- "valid"#
waterSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
waterData <- rep("train",120)#
#randomly replace half of the data to be validating data#
waterData[waterSamp] <- "valid"#
agriSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
agriData <- rep("train",120)#
#randomly replace half of the data to be validating data#
agriData[agriSamp] <- "valid"#
builtSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
builtData <- rep("train",120)#
#randomly replace half of the data to be validating data#
builtData[builtSamp] <- "valid"#
#
forestSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
forestData <- rep("train",120)#
#randomly replace half of the data to be validating data#
forestData[forestSamp] <- "valid"#
wetlandsSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
wetlandsData <- rep("train",120)#
#randomly replace half of the data to be validating data#
wetlandsData[wetlandsSamp] <- "valid"#
#
#set up raster dataframe#
#create id table that gives each landcover an ID#
landclass <- data.frame(landcID= seq(1,6),#
                        landcover = c("algal bloom", "open water","agriculture","built","forest","wetlands"))#
#
#set up table with coordinates and data type (validate or train) for each point#
landExtract <-  data.frame(landcID = rep(seq(1,6),each=120),#
                           sampleType=c(algData,waterData,agriData,builtData,forestData, wetlandsData),#
                           x=c(algae@coords[,1],water@coords[,1],agri@coords[,1],built@coords[,1],forest@coords[,1],wetlands@coords[,1] ),#
                           y=c(algae@coords[,2],water@coords[,2],agri@coords[,2],built@coords[,2],forest@coords[,2],wetlands@coords[,2] ))#
#
#extract raster data at each point#
#using point coordinates#
rasterEx <- data.frame(extract(allbandsCloudf,landExtract[,3:4]))#
#give names of bands#
colnames(rasterEx) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
#
#combine point information with raster information#
dataAll <- cbind(landExtract,rasterEx)#
#preview#
head(dataAll)#
#
#separate training and validation data#
trainD <- dataAll[dataAll$sampleType == "train",]#
validD <- dataAll[dataAll$sampleType == "valid",]#
#
#caret package helps tune the parameters#
#Kfold cross validation#
tc <- trainControl(method = "repeatedcv", # repeated cross-validation of the training data#
                   number = 10, # number 10 fold#
                   repeats = 10) # number of repeats#
###random forests#
#Typically square root of number of variables#
rf.grid <- expand.grid(mtry=1:sqrt(9)) # number of variables available for splitting at each tree node#
#
#we are using repeated cross validation method. #
#there is one parameter we can tune using caret: mtry#
#
#now train the model with our training dataset through the caret package#
# Train the random forest model to the Sentinel-2 data#
#note that caret:: will make sure we use train from the caret package#
trainD <- na.omit(trainD) # 3 NAs
# Change name in raster stack to match training data#
names(allbandsCloudf) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
# Apply the random forest model to the Sentinel-2 data#
rf_prediction <- raster::predict(allbandsCloudf, model=rf_model)#
#view predictions#
plot(rf_prediction)
rf_model <- caret::train(x = trainD[,c(5:13)], #digital number data#
                         y = as.factor(trainD$landcID), #land class we want to predict#
                         method = "rf", #use random forest#
                         metric="Accuracy", #assess by accuracy#
                         trainControl = tc, #use parameter tuning method#
                         tuneGrid = rf.grid) #parameter tuning grid#
#check output#
rf_model
names(allbandsCloudf) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
# Apply the random forest model to the Sentinel-2 data#
rf_prediction <- raster::predict(allbandsCloudf, model=rf_model)#
#view predictions#
plot(rf_prediction)
landclass
#set up categorical colors#
landclass$cols <-c("#a6d854","#8da0cb","#66c2a5",#
    "#fc8d62","#ffffb3","#ffd92f")#
#make plot and hide legend#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")
#get validation data from raster by extracting #
#cell values at the cell coordinates#
rf_Eval <- extract(rf_prediction, validD[,3:4])#
#make the confusion matrix#
rf_errorM <- confusionMatrix(as.factor(rf_Eval),as.factor(validD$landcID))#
#add landcover names#
colnames(rf_errorM$table) <- landclass$landcover#
rownames(rf_errorM$table) <- landclass$landcover#
#view the matrix#
rf_errorM$table#
#
#look at the overall accuracy#
rf_errorM$overall
nnet.grid <- expand.grid(size = seq(from = 16, to = 28, by = 2), # number of neurons units in the hidden layer #
                        decay = seq(from = 0.1, to = 0.6, by = 0.1)) # regularization parameter to avoid over-fitting
nnet_model <- caret::train(x = trainD[,c(5:13)], y = as.factor(trainD$landcID),#
                           method = "nnet", metric="Accuracy", trainControl = tc, tuneGrid = nnet.grid,#
                           trace=FALSE)#
nnet_model#
#
# Apply the neural network model to the Sentinel-2 data#
nnet_prediction <- raster::predict(allbandsCloudf, model=nnet_model)#
#make plot and hide legend
nn_Eval = extract(nnet_prediction, validD[,3:4])#
#confusion matrix#
nn_errorM = confusionMatrix(as.factor(nn_Eval),as.factor(validD$landcID))#
colnames(nn_errorM$table) <- landclass$landcover#
rownames(nn_errorM$table) <- landclass$landcover#
nn_errorM$table#
nn_errorM$overall
#comparing methods#
par(mfrow=c(2,1), mai=c(0,0,0,0))#
#random forest#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE)#
#legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")#
#add title#
mtext("Random Forest", side=3,cex=2, line=-5)#
#
#neural network#
plot(nnet_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
#add legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols, bty="n")   #
#add title#
mtext("Neural network", side=3,cex=2, line=-5)#
#
#QUESTION 3#
rf_errorM$table#
nn_errorM$table
yes
Yes
library(raster)#
library(sp)#
library(rgdal)#
library(rgeos)#
library(mapview)#
library(caret)#
library(randomForest)#
library(nnet)#
#
#set up directory for oneida data folder#
dirR <- "~/Downloads/mmaloney/a07"#
#
#read in Sentinel data#
#
rdatB2 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B02_20m.tif"))#
rdatB3 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B03_20m.tif"))#
rdatB4 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B04_20m.tif"))#
rdatB5 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B05_20m.tif"))#
rdatB6 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B06_20m.tif"))#
rdatB7 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B07_20m.tif"))#
rdatB8 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B08_20m.tif"))#
rdatB11 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B11_20m.tif"))#
rdatB12 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B12_20m.tif"))#
clouds <- raster(paste0(dirR,"/sentinel/MSK_CLDPRB_20m.tif"))
#read in validation data#
#here verbose=FALSE hiddes#
algae <- readOGR(paste0(dirR,"/Oneida/algae.shp"), verbose=FALSE)#
agri <- readOGR(paste0(dirR,"/Oneida/agriculture.shp"), verbose=FALSE)#
built <- readOGR(paste0(dirR,"/Oneida/built.shp"), verbose=FALSE)#
forest <- readOGR(paste0(dirR,"/Oneida/forest.shp"), verbose=FALSE)#
water <- readOGR(paste0(dirR,"/Oneida/water.shp"), verbose=FALSE)#
wetlands <- readOGR(paste0(dirR,"/Oneida/wetlands.shp"), verbose=FALSE)#
#
#stack red green blue#
rgbS <- stack(rdatB4,rdatB3,rdatB2)#
#stack all raster data#
allbands <- stack(rdatB2,rdatB3,rdatB4,rdatB5,rdatB6,rdatB7, rdatB8,rdatB11, rdatB12,clouds)
#set clouds to NA#
allbandsCloud <- list()#
for(i in 1:9){#
  allbandsCloud[[i]] <- setValues(allbands[[i]],#
                                  ifelse(getValues(allbands[[10]])>60,NA,getValues(allbands[[i]])))#
}#
allbandsCloudf <- stack(allbandsCloud[[1]],allbandsCloud[[2]],allbandsCloud[[3]],allbandsCloud[[4]],allbandsCloud[[5]],allbandsCloud[[6]],allbandsCloud[[7]],allbandsCloud[[8]],allbandsCloud[[9]])
#set seed so samples always the same#
set.seed(12153)#
#
#make a vector that indicates which of our our 120 points are going to be training vs validation data for each point.#
#randomly select #
algSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
algData <- rep("train",120)#
#randomly replace half of the data to be validating data#
algData[algSamp] <- "valid"#
#
set.seed(12153)#
waterSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
waterData <- rep("train",120)#
#randomly replace half of the data to be validating data#
waterData[waterSamp] <- "valid"#
#
set.seed(12153)#
agriSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
agriData <- rep("train",120)#
#randomly replace half of the data to be validating data#
agriData[agriSamp] <- "valid"#
#
set.seed(12153)#
builtSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
builtData <- rep("train",120)#
#randomly replace half of the data to be validating data#
builtData[builtSamp] <- "valid"#
#
set.seed(12153)#
forestSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
forestData <- rep("train",120)#
#randomly replace half of the data to be validating data#
forestData[forestSamp] <- "valid"#
#
set.seed(12153)#
wetlandsSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
wetlandsData <- rep("train",120)#
#randomly replace half of the data to be validating data#
wetlandsData[wetlandsSamp] <- "valid"#
#
#set up raster dataframe#
#create id table that gives each landcover an ID#
set.seed(12153)#
landclass <- data.frame(landcID= seq(1,6),#
                        landcover = c("algal bloom", "open water","agriculture","built","forest","wetlands"))#
#
#set up table with coordinates and data type (validate or train) for each point#
set.seed(12153)#
landExtract <-  data.frame(landcID = rep(seq(1,6),each=120),#
                           sampleType=c(algData,waterData,agriData,builtData,forestData, wetlandsData),#
                           x=c(algae@coords[,1],water@coords[,1],agri@coords[,1],built@coords[,1],forest@coords[,1],wetlands@coords[,1] ),#
                           y=c(algae@coords[,2],water@coords[,2],agri@coords[,2],built@coords[,2],forest@coords[,2],wetlands@coords[,2] ))#
#
#extract raster data at each point#
#using point coordinates#
set.seed(12153)#
rasterEx <- data.frame(extract(allbandsCloudf,landExtract[,3:4]))#
#give names of bands#
colnames(rasterEx) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
#
#combine point information with raster information#
dataAll <- cbind(landExtract,rasterEx)#
#preview#
head(dataAll)#
#
#separate training and validation data#
set.seed(12153)#
trainD <- dataAll[dataAll$sampleType == "train",]#
set.seed(12153)#
validD <- dataAll[dataAll$sampleType == "valid",]#
#
#caret package helps tune the parameters#
#Kfold cross validation#
set.seed(12153)#
tc <- trainControl(method = "repeatedcv", # repeated cross-validation of the training data#
                   number = 10, # number 10 fold#
                   repeats = 10) # number of repeats#
###random forests#
#Typically square root of number of variables#
set.seed(12153)#
rf.grid <- expand.grid(mtry=1:sqrt(9)) # number of variables available for splitting at each tree node#
#
#we are using repeated cross validation method. #
#there is one parameter we can tune using caret: mtry#
#
#now train the model with our training dataset through the caret package#
# Train the random forest model to the Sentinel-2 data#
#note that caret:: will make sure we use train from the caret package#
#trainD <- na.omit(trainD) # 3 NAs#
set.seed(12153)#
rf_model <- caret::train(x = trainD[,c(5:13)], #digital number data#
                         y = as.factor(trainD$landcID), #land class we want to predict#
                         method = "rf", #use random forest#
                         metric="Accuracy", #assess by accuracy#
                         trainControl = tc, #use parameter tuning method#
                         tuneGrid = rf.grid) #parameter tuning grid#
#check output#
rf_model#
#
# Change name in raster stack to match training data#
names(allbandsCloudf) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
# Apply the random forest model to the Sentinel-2 data#
set.seed(12153)#
rf_prediction <- raster::predict(allbandsCloudf, model=rf_model)#
#view predictions#
plot(rf_prediction)#
#
#landcover class names#
landclass#
#
#set up categorical colors#
landclass$cols <-c("#a6d854","#8da0cb","#66c2a5",#
    "#fc8d62","#ffffb3","#ffd92f")#
#make plot and hide legend#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")  #
#
#get validation data from raster by extracting #
#cell values at the cell coordinates#
set.seed(12153)#
rf_Eval <- extract(rf_prediction, validD[,3:4])#
#make the confusion matrix#
set.seed(12153)#
rf_errorM <- confusionMatrix(as.factor(rf_Eval),as.factor(validD$landcID))#
#add landcover names#
colnames(rf_errorM$table) <- landclass$landcover#
rownames(rf_errorM$table) <- landclass$landcover#
#view the matrix#
rf_errorM$table#
#
#look at the overall accuracy#
rf_errorM$overall#
#
# QUESTION 2#
# what landclasses have the highest rates of misclassification?#
 # agriculture has the highest rate of misclassification. it is misclassified about 27% of the time, while the others are less than 10%. #
# what sort of bias would this introduce if you used these predictions in an analysis#
 # this would bias the data in that it would predict a lot less agricultural land than there actually is
#install.packages(c("mapview","caret","randomForest","nnet"))#
library(raster)#
library(sp)#
library(rgdal)#
library(rgeos)#
library(mapview)#
library(caret)#
library(randomForest)#
library(nnet)#
#
#set up directory for oneida data folder#
dirR <- "~/Downloads/mmaloney/a07"#
#
#read in Sentinel data#
#
rdatB2 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B02_20m.tif"))#
rdatB3 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B03_20m.tif"))#
rdatB4 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B04_20m.tif"))#
rdatB5 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B05_20m.tif"))#
rdatB6 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B06_20m.tif"))#
rdatB7 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B07_20m.tif"))#
rdatB8 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B08_20m.tif"))#
rdatB11 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B11_20m.tif"))#
rdatB12 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B12_20m.tif"))#
clouds <- raster(paste0(dirR,"/sentinel/MSK_CLDPRB_20m.tif"))#
#
#read in validation data#
#here verbose=FALSE hiddes#
algae <- readOGR(paste0(dirR,"/Oneida/algae.shp"), verbose=FALSE)#
agri <- readOGR(paste0(dirR,"/Oneida/agriculture.shp"), verbose=FALSE)#
built <- readOGR(paste0(dirR,"/Oneida/built.shp"), verbose=FALSE)#
forest <- readOGR(paste0(dirR,"/Oneida/forest.shp"), verbose=FALSE)#
water <- readOGR(paste0(dirR,"/Oneida/water.shp"), verbose=FALSE)#
wetlands <- readOGR(paste0(dirR,"/Oneida/wetlands.shp"), verbose=FALSE)#
#
#stack red green blue#
rgbS <- stack(rdatB4,rdatB3,rdatB2)#
#stack all raster data#
allbands <- stack(rdatB2,rdatB3,rdatB4,rdatB5,rdatB6,rdatB7, rdatB8,rdatB11, rdatB12,clouds)
#set clouds to NA#
allbandsCloud <- list()#
for(i in 1:9){#
  allbandsCloud[[i]] <- setValues(allbands[[i]],#
                                  ifelse(getValues(allbands[[10]])>60,NA,getValues(allbands[[i]])))#
}#
allbandsCloudf <- stack(allbandsCloud[[1]],allbandsCloud[[2]],allbandsCloud[[3]],allbandsCloud[[4]],allbandsCloud[[5]],allbandsCloud[[6]],allbandsCloud[[7]],allbandsCloud[[8]],allbandsCloud[[9]])
#set seed so samples always the same#
set.seed(12153)#
#
#make a vector that indicates which of our our 120 points are going to be training vs validation data for each point.#
#randomly select #
algSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
algData <- rep("train",120)#
#randomly replace half of the data to be validating data#
algData[algSamp] <- "valid"#
#
set.seed(12153)#
waterSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
waterData <- rep("train",120)#
#randomly replace half of the data to be validating data#
waterData[waterSamp] <- "valid"#
#
set.seed(12153)#
agriSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
agriData <- rep("train",120)#
#randomly replace half of the data to be validating data#
agriData[agriSamp] <- "valid"#
#
set.seed(12153)#
builtSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
builtData <- rep("train",120)#
#randomly replace half of the data to be validating data#
builtData[builtSamp] <- "valid"#
#
set.seed(12153)#
forestSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
forestData <- rep("train",120)#
#randomly replace half of the data to be validating data#
forestData[forestSamp] <- "valid"#
#
set.seed(12153)#
wetlandsSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
wetlandsData <- rep("train",120)#
#randomly replace half of the data to be validating data#
wetlandsData[wetlandsSamp] <- "valid"#
#
#set up raster dataframe#
#create id table that gives each landcover an ID#
set.seed(12153)#
landclass <- data.frame(landcID= seq(1,6),#
                        landcover = c("algal bloom", "open water","agriculture","built","forest","wetlands"))#
#
#set up table with coordinates and data type (validate or train) for each point#
set.seed(12153)#
landExtract <-  data.frame(landcID = rep(seq(1,6),each=120),#
                           sampleType=c(algData,waterData,agriData,builtData,forestData, wetlandsData),#
                           x=c(algae@coords[,1],water@coords[,1],agri@coords[,1],built@coords[,1],forest@coords[,1],wetlands@coords[,1] ),#
                           y=c(algae@coords[,2],water@coords[,2],agri@coords[,2],built@coords[,2],forest@coords[,2],wetlands@coords[,2] ))#
#
#extract raster data at each point#
#using point coordinates#
set.seed(12153)#
rasterEx <- data.frame(extract(allbandsCloudf,landExtract[,3:4]))#
#give names of bands#
colnames(rasterEx) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
#
#combine point information with raster information#
dataAll <- cbind(landExtract,rasterEx)#
#preview#
head(dataAll)#
#
#separate training and validation data#
set.seed(12153)#
trainD <- dataAll[dataAll$sampleType == "train",]#
set.seed(12153)#
validD <- dataAll[dataAll$sampleType == "valid",]#
#
#caret package helps tune the parameters#
#Kfold cross validation#
set.seed(12153)#
tc <- trainControl(method = "repeatedcv", # repeated cross-validation of the training data#
                   number = 10, # number 10 fold#
                   repeats = 10) # number of repeats#
###random forests#
#Typically square root of number of variables#
set.seed(12153)#
rf.grid <- expand.grid(mtry=1:sqrt(9)) # number of variables available for splitting at each tree node#
#
#we are using repeated cross validation method. #
#there is one parameter we can tune using caret: mtry#
#
#now train the model with our training dataset through the caret package#
# Train the random forest model to the Sentinel-2 data#
#note that caret:: will make sure we use train from the caret package#
trainD <- na.omit(trainD) # 3 NAs#
set.seed(12153)#
rf_model <- caret::train(x = trainD[,c(5:13)], #digital number data#
                         y = as.factor(trainD$landcID), #land class we want to predict#
                         method = "rf", #use random forest#
                         metric="Accuracy", #assess by accuracy#
                         trainControl = tc, #use parameter tuning method#
                         tuneGrid = rf.grid) #parameter tuning grid#
#check output#
rf_model#
#
# Change name in raster stack to match training data#
names(allbandsCloudf) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
# Apply the random forest model to the Sentinel-2 data#
set.seed(12153)#
rf_prediction <- raster::predict(allbandsCloudf, model=rf_model)#
#view predictions#
plot(rf_prediction)#
#
#landcover class names#
landclass#
#
#set up categorical colors#
landclass$cols <-c("#a6d854","#8da0cb","#66c2a5",#
    "#fc8d62","#ffffb3","#ffd92f")#
#make plot and hide legend#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")  #
#
#get validation data from raster by extracting #
#cell values at the cell coordinates#
set.seed(12153)#
rf_Eval <- extract(rf_prediction, validD[,3:4])#
#make the confusion matrix#
set.seed(12153)#
rf_errorM <- confusionMatrix(as.factor(rf_Eval),as.factor(validD$landcID))#
#add landcover names#
colnames(rf_errorM$table) <- landclass$landcover#
rownames(rf_errorM$table) <- landclass$landcover#
#view the matrix#
rf_errorM$table#
#
#look at the overall accuracy#
rf_errorM$overall
#Neural Networks approach#
#set up grid#
set.seed(12153)#
nnet.grid <- expand.grid(size = seq(from = 16, to = 28, by = 2), # number of neurons units in the hidden layer #
                        decay = seq(from = 0.1, to = 0.6, by = 0.1)) # regularization parameter to avoid over-fitting #
set.seed(12153)#
nnet_model <- caret::train(x = trainD[,c(5:13)], y = as.factor(trainD$landcID),#
                           method = "nnet", metric="Accuracy", trainControl = tc, tuneGrid = nnet.grid,#
                           trace=FALSE)#
nnet_model#
#
# Apply the neural network model to the Sentinel-2 data#
set.seed(12153)#
nnet_prediction <- raster::predict(allbandsCloudf, model=nnet_model)#
#make plot and hide legend#
plot(nnet_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE)#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")#
#
#extract predictions#
set.seed(12153)#
nn_Eval = extract(nnet_prediction, validD[,3:4])#
#confusion matrix#
set.seed(12153)#
nn_errorM = confusionMatrix(as.factor(nn_Eval),as.factor(validD$landcID))#
colnames(nn_errorM$table) <- landclass$landcover#
rownames(nn_errorM$table) <- landclass$landcover#
nn_errorM$table#
nn_errorM$overall#
#
#comparing methods#
par(mfrow=c(2,1), mai=c(0,0,0,0))#
#random forest#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE)#
#legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")#
#add title#
mtext("Random Forest", side=3,cex=2, line=-5)#
#
#neural network#
plot(nnet_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
#add legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols, bty="n")   #
#add title#
mtext("Neural network", side=3,cex=2, line=-5)#
#
#QUESTION 3#
rf_errorM$table#
nn_errorM$table
#install.packages(c("mapview","caret","randomForest","nnet"))#
library(raster)#
library(sp)#
library(rgdal)#
library(rgeos)#
library(mapview)#
library(caret)#
library(randomForest)#
library(nnet)#
#
#set up directory for oneida data folder#
dirR <- "~/Downloads/mmaloney/a07"#
#
#read in Sentinel data
rdatB2 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B02_20m.tif"))#
rdatB3 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B03_20m.tif"))#
rdatB4 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B04_20m.tif"))#
rdatB5 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B05_20m.tif"))#
rdatB6 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B06_20m.tif"))#
rdatB7 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B07_20m.tif"))#
rdatB8 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B08_20m.tif"))#
rdatB11 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B11_20m.tif"))#
rdatB12 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B12_20m.tif"))#
clouds <- raster(paste0(dirR,"/sentinel/MSK_CLDPRB_20m.tif"))#
#
#read in validation data#
#here verbose=FALSE hiddes#
algae <- readOGR(paste0(dirR,"/Oneida/algae.shp"), verbose=FALSE)#
agri <- readOGR(paste0(dirR,"/Oneida/agriculture.shp"), verbose=FALSE)#
built <- readOGR(paste0(dirR,"/Oneida/built.shp"), verbose=FALSE)#
forest <- readOGR(paste0(dirR,"/Oneida/forest.shp"), verbose=FALSE)#
water <- readOGR(paste0(dirR,"/Oneida/water.shp"), verbose=FALSE)#
wetlands <- readOGR(paste0(dirR,"/Oneida/wetlands.shp"), verbose=FALSE)#
#
#stack red green blue#
rgbS <- stack(rdatB4,rdatB3,rdatB2)#
#stack all raster data#
allbands <- stack(rdatB2,rdatB3,rdatB4,rdatB5,rdatB6,rdatB7, rdatB8,rdatB11, rdatB12,clouds)#
#
#view raster, maximum digigtal is around 20000 so set scale to that
#set clouds to NA#
allbandsCloud <- list()#
for(i in 1:9){#
  allbandsCloud[[i]] <- setValues(allbands[[i]],#
                                  ifelse(getValues(allbands[[10]])>60,NA,getValues(allbands[[i]])))#
}#
allbandsCloudf <- stack(allbandsCloud[[1]],allbandsCloud[[2]],allbandsCloud[[3]],allbandsCloud[[4]],allbandsCloud[[5]],allbandsCloud[[6]],allbandsCloud[[7]],allbandsCloud[[8]],allbandsCloud[[9]])
set.seed(500)
#make a vector that indicates which of our our 120 points are going to be training vs validation data for each point.#
#randomly select #
algSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
algData <- rep("train",120)#
#randomly replace half of the data to be validating data#
algData[algSamp] <- "valid"#
#
#set.seed(12153)#
waterSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
waterData <- rep("train",120)#
#randomly replace half of the data to be validating data#
waterData[waterSamp] <- "valid"#
#
#set.seed(12153)#
agriSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
agriData <- rep("train",120)#
#randomly replace half of the data to be validating data#
agriData[agriSamp] <- "valid"#
#
#set.seed(12153)#
builtSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
builtData <- rep("train",120)#
#randomly replace half of the data to be validating data#
builtData[builtSamp] <- "valid"#
#
#set.seed(12153)#
forestSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
forestData <- rep("train",120)#
#randomly replace half of the data to be validating data#
forestData[forestSamp] <- "valid"#
#
#set.seed(12153)#
wetlandsSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
wetlandsData <- rep("train",120)#
#randomly replace half of the data to be validating data#
wetlandsData[wetlandsSamp] <- "valid"#
#
#set up raster dataframe#
#create id table that gives each landcover an ID#
#set.seed(12153)#
landclass <- data.frame(landcID= seq(1,6),#
                        landcover = c("algal bloom", "open water","agriculture","built","forest","wetlands"))#
#
#set up table with coordinates and data type (validate or train) for each point#
#set.seed(12153)#
landExtract <-  data.frame(landcID = rep(seq(1,6),each=120),#
                           sampleType=c(algData,waterData,agriData,builtData,forestData, wetlandsData),#
                           x=c(algae@coords[,1],water@coords[,1],agri@coords[,1],built@coords[,1],forest@coords[,1],wetlands@coords[,1] ),#
                           y=c(algae@coords[,2],water@coords[,2],agri@coords[,2],built@coords[,2],forest@coords[,2],wetlands@coords[,2] ))#
#
#extract raster data at each point#
#using point coordinates#
#set.seed(12153)#
rasterEx <- data.frame(extract(allbandsCloudf,landExtract[,3:4]))#
#give names of bands#
colnames(rasterEx) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
#
#combine point information with raster information#
dataAll <- cbind(landExtract,rasterEx)#
#preview#
head(dataAll)#
#
#separate training and validation data#
#set.seed(12153)#
trainD <- dataAll[dataAll$sampleType == "train",]#
#set.seed(12153)#
validD <- dataAll[dataAll$sampleType == "valid",]#
#
#caret package helps tune the parameters#
#Kfold cross validation#
#set.seed(12153)#
tc <- trainControl(method = "repeatedcv", # repeated cross-validation of the training data#
                   number = 10, # number 10 fold#
                   repeats = 10) # number of repeats#
###random forests#
#Typically square root of number of variables#
#set.seed(12153)#
rf.grid <- expand.grid(mtry=1:sqrt(9)) # number of variables available for splitting at each tree node#
#
#we are using repeated cross validation method. #
#there is one parameter we can tune using caret: mtry#
#
#now train the model with our training dataset through the caret package#
# Train the random forest model to the Sentinel-2 data#
#note that caret:: will make sure we use train from the caret package#
trainD <- na.omit(trainD) # 3 NAs#
#set.seed(12153)#
rf_model <- caret::train(x = trainD[,c(5:13)], #digital number data#
                         y = as.factor(trainD$landcID), #land class we want to predict#
                         method = "rf", #use random forest#
                         metric="Accuracy", #assess by accuracy#
                         trainControl = tc, #use parameter tuning method#
                         tuneGrid = rf.grid) #parameter tuning grid#
#check output#
rf_model#
#
# Change name in raster stack to match training data#
names(allbandsCloudf) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
# Apply the random forest model to the Sentinel-2 data#
#set.seed(12153)#
rf_prediction <- raster::predict(allbandsCloudf, model=rf_model)#
#view predictions#
plot(rf_prediction)#
#
#landcover class names#
landclass#
#
#set up categorical colors#
landclass$cols <-c("#a6d854","#8da0cb","#66c2a5",#
    "#fc8d62","#ffffb3","#ffd92f")#
#make plot and hide legend#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")  #
#
#get validation data from raster by extracting #
#cell values at the cell coordinates#
#set.seed(12153)#
rf_Eval <- extract(rf_prediction, validD[,3:4])#
#make the confusion matrix#
#set.seed(12153)#
rf_errorM <- confusionMatrix(as.factor(rf_Eval),as.factor(validD$landcID))#
#add landcover names#
colnames(rf_errorM$table) <- landclass$landcover#
rownames(rf_errorM$table) <- landclass$landcover#
#view the matrix#
rf_errorM$table#
#
#look at the overall accuracy#
rf_errorM$overall#
#
# QUESTION 2#
# what landclasses have the highest rates of misclassification?#
 # agriculture has the highest rate of misclassification. it is misclassified about 27% of the time, while the others are less than 10%. #
# what sort of bias would this introduce if you used these predictions in an analysis#
 # this would bias the data in that it would predict a lot less agricultural land than there actually is#
#
#Neural Networks approach#
#set up grid#
#set.seed(12153)#
nnet.grid <- expand.grid(size = seq(from = 16, to = 28, by = 2), # number of neurons units in the hidden layer #
                        decay = seq(from = 0.1, to = 0.6, by = 0.1)) # regularization parameter to avoid over-fitting #
#set.seed(12153)#
nnet_model <- caret::train(x = trainD[,c(5:13)], y = as.factor(trainD$landcID),#
                           method = "nnet", metric="Accuracy", trainControl = tc, tuneGrid = nnet.grid,#
                           trace=FALSE)#
nnet_model#
#
# Apply the neural network model to the Sentinel-2 data#
#set.seed(12153)#
nnet_prediction <- raster::predict(allbandsCloudf, model=nnet_model)#
#make plot and hide legend#
plot(nnet_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE)#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")#
#
#extract predictions#
#set.seed(12153)#
nn_Eval = extract(nnet_prediction, validD[,3:4])#
#confusion matrix#
#set.seed(12153)#
nn_errorM = confusionMatrix(as.factor(nn_Eval),as.factor(validD$landcID))#
colnames(nn_errorM$table) <- landclass$landcover#
rownames(nn_errorM$table) <- landclass$landcover#
nn_errorM$table#
nn_errorM$overall#
#
#comparing methods#
par(mfrow=c(2,1), mai=c(0,0,0,0))#
#random forest#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE)#
#legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")#
#add title#
mtext("Random Forest", side=3,cex=2, line=-5)#
#
#neural network#
plot(nnet_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
#add legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols, bty="n")   #
#add title#
mtext("Neural network", side=3,cex=2, line=-5)#
#
#QUESTION 3#
rf_errorM$table#
nn_errorM$table
(freq(nnet_prediction)[1,2]*400)-(freq(rf_prediction)[1,2]*400)
#QUESTION 5#
diffRaster<-rf_prediction==nnet_prediction#
plot(diffRaster, col=c("firebrick","darkolivegreen2"), legend=FALSE, axes=FALSE)#
legend("bottomleft", legend=c("Predictions Disagree","Predictions Agree"),#
fill=c("firebrick", "darkolivegreen2"))
par(mfrow=c(2,1), mai=c(0,0,0,0))#
#random forest#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE)#
#legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")#
#add title#
mtext("Random Forest", side=3,cex=2, line=-5)#
#
#neural network#
plot(nnet_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
#add legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols, bty="n")   #
#add title#
mtext("Neural network", side=3,cex=2, line=-5)
#install.packages(c("mapview","caret","randomForest","nnet"))#
library(raster)#
library(sp)#
library(rgdal)#
library(rgeos)#
library(mapview)#
library(caret)#
library(randomForest)#
library(nnet)#
#
#set up directory for oneida data folder#
dirR <- "~/Downloads/mmaloney/a07"#
#
#read in Sentinel data#
#
rdatB2 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B02_20m.tif"))#
rdatB3 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B03_20m.tif"))#
rdatB4 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B04_20m.tif"))#
rdatB5 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B05_20m.tif"))#
rdatB6 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B06_20m.tif"))#
rdatB7 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B07_20m.tif"))#
rdatB8 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B08_20m.tif"))#
rdatB11 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B11_20m.tif"))#
rdatB12 <- raster(paste0(dirR,"/sentinel/T18TVN_20190814T154911_B12_20m.tif"))#
clouds <- raster(paste0(dirR,"/sentinel/MSK_CLDPRB_20m.tif"))#
#
#read in validation data#
#here verbose=FALSE hiddes#
algae <- readOGR(paste0(dirR,"/Oneida/algae.shp"), verbose=FALSE)#
agri <- readOGR(paste0(dirR,"/Oneida/agriculture.shp"), verbose=FALSE)#
built <- readOGR(paste0(dirR,"/Oneida/built.shp"), verbose=FALSE)#
forest <- readOGR(paste0(dirR,"/Oneida/forest.shp"), verbose=FALSE)#
water <- readOGR(paste0(dirR,"/Oneida/water.shp"), verbose=FALSE)#
wetlands <- readOGR(paste0(dirR,"/Oneida/wetlands.shp"), verbose=FALSE)#
#
#stack red green blue#
rgbS <- stack(rdatB4,rdatB3,rdatB2)#
#stack all raster data#
allbands <- stack(rdatB2,rdatB3,rdatB4,rdatB5,rdatB6,rdatB7, rdatB8,rdatB11, rdatB12,clouds)
#set clouds to NA#
allbandsCloud <- list()#
for(i in 1:9){#
  allbandsCloud[[i]] <- setValues(allbands[[i]],#
                                  ifelse(getValues(allbands[[10]])>60,NA,getValues(allbands[[i]])))#
}#
allbandsCloudf <- stack(allbandsCloud[[1]],allbandsCloud[[2]],allbandsCloud[[3]],allbandsCloud[[4]],allbandsCloud[[5]],allbandsCloud[[6]],allbandsCloud[[7]],allbandsCloud[[8]],allbandsCloud[[9]])
set.seed(50)#
#
#make a vector that indicates which of our our 120 points are going to be training vs validation data for each point.#
#randomly select #
algSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
algData <- rep("train",120)#
#randomly replace half of the data to be validating data#
algData[algSamp] <- "valid"#
#
waterSamp <- sort(sample(seq(1,120),60))#
#set up vector for data type#
waterData <- rep("train",120)#
#randomly replace half of the data to be validating data#
waterData[waterSamp] <- "valid"#
#
agriSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
agriData <- rep("train",120)#
#randomly replace half of the data to be validating data#
agriData[agriSamp] <- "valid"#
#
builtSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
builtData <- rep("train",120)#
#randomly replace half of the data to be validating data#
builtData[builtSamp] <- "valid"#
#
forestSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
forestData <- rep("train",120)#
#randomly replace half of the data to be validating data#
forestData[forestSamp] <- "valid"#
#
wetlandsSamp  <- sort(sample(seq(1,120),60))#
#set up vector for data type#
wetlandsData <- rep("train",120)#
#randomly replace half of the data to be validating data#
wetlandsData[wetlandsSamp] <- "valid"#
#
#set up raster dataframe#
#create id table that gives each landcover an ID#
landclass <- data.frame(landcID= seq(1,6),#
                        landcover = c("algal bloom", "open water","agriculture","built","forest","wetlands"))#
#
#set up table with coordinates and data type (validate or train) for each point#
landExtract <-  data.frame(landcID = rep(seq(1,6),each=120),#
                           sampleType=c(algData,waterData,agriData,builtData,forestData, wetlandsData),#
                           x=c(algae@coords[,1],water@coords[,1],agri@coords[,1],built@coords[,1],forest@coords[,1],wetlands@coords[,1] ),#
                           y=c(algae@coords[,2],water@coords[,2],agri@coords[,2],built@coords[,2],forest@coords[,2],wetlands@coords[,2] ))#
#
#extract rast
rasterEx <- data.frame(extract(allbandsCloudf,landExtract[,3:4]))#
#give names of bands#
colnames(rasterEx) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
#
#combine point information with raster information#
dataAll <- cbind(landExtract,rasterEx)#
#preview#
head(dataAll)#
#
#separate training and validation data#
trainD <- dataAll[dataAll$sampleType == "train",]#
validD <- dataAll[dataAll$sampleType == "valid",]#
#
#caret package helps tune the parameters#
#Kfold cross validation#
tc <- trainControl(method = "repeatedcv", # repeated cross-validation of the training data#
                   number = 10, # number 10 fold#
                   repeats = 10) # number of repeats#
###random forests#
#Typically square root of number of variables#
rf.grid <- expand.grid(mtry=1:sqrt(9)) # number of variables available for splitting at each tree node#
#
#we are using repeated cross validation method. #
#there is one parameter we can tune using caret: mtry#
#
#now train the model with our training dataset through the caret package#
# Train the random forest model to the Sentinel-2 data#
#note that caret:: will make sure we use train from the caret package#
trainD <- na.omit(trainD) # 3 NAs#
rf_model <- caret::train(x = trainD[,c(5:13)], #digital number data#
                         y = as.factor(trainD$landcID), #land class we want to predict#
                         method = "rf", #use random forest#
                         metric="Accuracy", #assess by accuracy#
                         trainControl = tc, #use parameter tuning method#
                         tuneGrid = rf.grid) #parameter tuning grid#
#check output#
rf_model#
#
# Change name in raster stack to match training data#
names(allbandsCloudf) <- c("B2","B3","B4","B5","B6","B7","B8","B11","B12")#
# Apply the random forest model to the Sentinel-2 data#
rf_prediction <- raster::predict(allbandsCloudf, model=rf_model)#
#view predictions#
plot(rf_prediction)#
#
#landcover class names#
landclass#
#
#set up categorical colors#
landclass$cols <-c("#a6d854","#8da0cb","#66c2a5",#
    "#fc8d62","#ffffb3","#ffd92f")#
#make plot and hide legend#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")  #
#
#get validation data from raster by extracting #
#cell values at the cell coordinates#
rf_Eval <- extract(rf_prediction, validD[,3:4])#
#make the confusion matrix#
rf_errorM <- confusionMatrix(as.factor(rf_Eval),as.factor(validD$landcID))#
#add landcover names#
colnames(rf_errorM$table) <- landclass$landcover#
rownames(rf_errorM$table) <- landclass$landcover#
#view the matrix#
rf_errorM$table#
#
#look at the overall accuracy#
rf_errorM$overall
# QUESTION 2#
# what landclasses have the highest rates of misclassification?#
 # agriculture has the highest rate of misclassification. it is misclassified about 27% of the time, while the others are less than 10%. #
# what sort of bias would this introduce if you used these predictions in an analysis#
 # this would bias the data in that it would predict a lot less agricultural land than there actually is#
#
#Neural Networks approach#
#set up grid#
nnet.grid <- expand.grid(size = seq(from = 16, to = 28, by = 2), # number of neurons units in the hidden layer #
                        decay = seq(from = 0.1, to = 0.6, by = 0.1)) # regularization parameter to avoid over-fitting #
nnet_model <- caret::train(x = trainD[,c(5:13)], y = as.factor(trainD$landcID),#
                           method = "nnet", metric="Accuracy", trainControl = tc, tuneGrid = nnet.grid,#
                           trace=FALSE)#
nnet_model#
#
# Apply the neural network model to the Sentinel-2 data#
nnet_prediction <- raster::predict(allbandsCloudf, model=nnet_model)#
#make plot and hide legend#
plot(nnet_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE)#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")#
#
#extract predictions#
nn_Eval = extract(nnet_prediction, validD[,3:4])#
#confusion matrix#
nn_errorM = confusionMatrix(as.factor(nn_Eval),as.factor(validD$landcID))#
colnames(nn_errorM$table) <- landclass$landcover#
rownames(nn_errorM$table) <- landclass$landcover#
nn_errorM$table#
nn_errorM$overall#
#
#comparing methods#
par(mfrow=c(2,1), mai=c(0,0,0,0))#
#random forest#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE)#
#legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")#
#add title#
mtext("Random Forest", side=3,cex=2, line=-5)#
#
#neural network#
plot(nnet_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
#add legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols, bty="n")   #
#add title#
mtext("Neural network", side=3,cex=2, line=-5)#
#
#QUESTION 3#
rf_errorM$table#
nn_errorM$table#
#
#Analyzing predictions#
#cell count neural net#
freq(nnet_prediction)#
#cell count random forest#
freq(rf_prediction)#
#
#QUESTION 4#
(freq(nnet_prediction)[1,2]*400)-(freq(rf_prediction)[1,2]*400)#
#QUESTION 5#
diffRaster<-rf_prediction==nnet_prediction#
plot(diffRaster, col=c("firebrick","darkolivegreen2"), legend=FALSE, axes=FALSE)#
legend("bottomleft", legend=c("Predictions Disagree","Predictions Agree"),#
fill=c("firebrick", "darkolivegreen2"))#
#QUESTION 6#
rf_errorM$table#
nn_errorM$table#
#
#QUESTION 7#
# algal blooms are prone to occur in areas where sunlight, stagnant water, and excess nutrient inputs can promote growth. Visually, do you think the landcover around the lake contributes to the algal blooms? #
# explain your answer#
	# it looks to me like the most algae is occurring in areas near forests. this could be explained by an excess of nutrients.#
# how would answer this question quantitatively using spatial analysis techniques?#
	# I would answer this question by creating a buffer around the algae and water to analyze what landcovers are most prominent when algae is and is not present. #
#
#QUESTION 8#
# which prediction method would you use for a more formal quantitative analysis of question 7? #
	# I would use random forests because it has a much higher accuracy.#
# what bias would you need to consider in the interpretation of your results?#
	##
#QUESTION 9#
# this type of prediction can only classify algal growth from a satellite measurement. what might be some of the issues with relying on satellites to observe the presence of algal blooms? #
# what data and approaches might you use to predict whether an algal bloom is expected to occur in the future
par(mfrow=c(2,1), mai=c(0,0,0,0))#
#random forest#
plot(rf_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE)#
#legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols ,bty="n")#
#add title#
mtext("Random Forest", side=3,cex=2, line=-5)#
#
#neural network#
plot(nnet_prediction,#
    breaks=seq(0,6), #
    col=landclass$cols ,#
    legend=FALSE, axes=FALSE)#
#add legend#
legend("bottomleft", paste(landclass$landcover),#
fill=landclass$cols, bty="n")   #
#add title#
mtext("Neural network", side=3,cex=2, line=-5)
diffRaster<-rf_prediction==nnet_prediction#
plot(diffRaster, col=c("firebrick","darkolivegreen2"), legend=FALSE, axes=FALSE)#
legend("bottomleft", legend=c("Predictions Disagree","Predictions Agree"),#
fill=c("firebrick", "darkolivegreen2"))
